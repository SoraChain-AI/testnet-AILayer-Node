{"text": "Methodological Approach for the Design of a Complex Inclusive Human-Machine System\n  Modern industrial automatic machines and robotic cells are equipped with\nhighly complex human-machine interfaces (HMIs) that often prevent human\noperators from an effective use of the automatic systems. In particular, this\napplies to vulnerable users, such as those with low experience or education\nlevel, the elderly and the disabled. To tackle this issue, it becomes necessary\nto design user-oriented HMIs, which adapt to the capabilities and skills of\nusers, thus compensating their limitations and taking full advantage of their\nknowledge. In this paper, we propose a methodological approach to the design of\ncomplex adaptive human-machine systems that might be inclusive of all users, in\nparticular the vulnerable ones. The proposed approach takes into account both\nthe technical requirements and the requirements for ethical, legal and social\nimplications (ELSI) for the design of automatic systems. The technical\nrequirements derive from a thorough analysis of three use cases taken from the\nEuropean project INCLUSIVE. To achieve the ELSI requirements, the MEESTAR\napproach is combined with the specific legal issues for occupational systems\nand requirements of the target users.\n", "pos": 5.507851799261988}
{"text": "Midgar: Detection of people through computer vision in the Internet of Things scenarios to improve the security in Smart Cities, Smart Towns, and Smart Homes\n  Could we use Computer Vision in the Internet of Things for using pictures as\nsensors? This is the principal hypothesis that we want to resolve. Currently,\nin order to create safety areas, cities, or homes, people use IP cameras.\nNevertheless, this system needs people who watch the camera images, watch the\nrecording after something occurred, or watch when the camera notifies them of\nany movement. These are the disadvantages. Furthermore, there are many Smart\nCities and Smart Homes around the world. This is why we thought of using the\nidea of the Internet of Things to add a way of automating the use of IP\ncameras. In our case, we propose the analysis of pictures through Computer\nVision to detect people in the analysed pictures. With this analysis, we are\nable to obtain if these pictures contain people and handle the pictures as if\nthey were sensors with two possible states. Notwithstanding, Computer Vision is\na very complicated field. This is why we needed a second hypothesis: Could we\nwork with Computer Vision in the Internet of Things with a good accuracy to\nautomate or semi-automate this kind of events? The demonstration of these\nhypotheses required a testing over our Computer Vision module to check the\npossibilities that we have to use this module in a possible real environment\nwith a good accuracy. Our proposal, as a possible solution, is the analysis of\nentire sequence instead of isolated pictures for using pictures as sensors in\nthe Internet of Things.\n", "pos": 5.350148914873185}
{"text": "Survey of Visual Question Answering: Datasets and Techniques\n  Visual question answering (or VQA) is a new and exciting problem that\ncombines natural language processing and computer vision techniques. We present\na survey of the various datasets and models that have been used to tackle this\ntask. The first part of the survey details the various datasets for VQA and\ncompares them along some common factors. The second part of this survey details\nthe different approaches for VQA, classified into four types: non-deep learning\nmodels, deep learning models without attention, deep learning models with\nattention, and other models which do not fit into the first three. Finally, we\ncompare the performances of these approaches and provide some directions for\nfuture work.\n", "pos": 5.337717445096114}
{"text": "Characterization of the Split Closure via Geometric Lifting\n  We analyze split cuts from the perspective of cut generating functions via\ngeometric lifting. We show that $\\alpha$-cuts, a natural higher-dimensional\ngeneralization of the $k$-cuts of Cornu\u00e9jols et al., gives all the split\ncuts for the mixed-integer corner relaxation. As an immediate consequence we\nobtain that the $k$-cuts are equivalent to split cuts for the 1-row\nmixed-integer relaxation. Further, we show that split cuts for\nfinite-dimensional corner relaxations are restrictions of split cuts for the\ninfinite-dimensional relaxation. In a final application of this equivalence, we\nexhibit a family of pure-integer programs whose split closures have arbitrarily\nbad integrality gap. This complements the mixed-integer example provided by\nBasu et al [On the relative strength of split, triangle and quadrilateral cuts,\nMath. Program. 126(2):281--314, 2011].\n", "pos": 5.214425095914701}
{"text": "Estimating thresholding levels for random fields via Euler characteristics\n  We introduce Lipschitz-Killing curvature (LKC) regression, a new method to\nproduce $(1-\\alpha)$ thresholds for signal detection in random fields that does\nnot require knowledge of the spatial correlation structure. The idea is to fit\nobserved empirical Euler characteristics to the Gaussian kinematic formula via\ngeneralized least squares, which quickly and easily provides statistical\nestimates of the LKCs --- complex topological quantities that can be extremely\nchallenging to compute, both theoretically and numerically. With these\nestimates, we can then make use of a powerful parametric approximation via\nEuler characteristics for Gaussian random fields to generate accurate\n$(1-\\alpha)$ thresholds and $p$-values. The main features of our proposed LKC\nregression method are easy implementation, conceptual simplicity, and\nfacilitated diagnostics, which we demonstrate in a variety of simulations and\napplications.\n", "pos": 5.438525305826048}
{"text": "Analysis of Extremely Obese Individuals Using Deep Learning Stacked Autoencoders and Genome-Wide Genetic Data\n  The aetiology of polygenic obesity is multifactorial, which indicates that\nlife-style and environmental factors may influence multiples genes to aggravate\nthis disorder. Several low-risk single nucleotide polymorphisms (SNPs) have\nbeen associated with BMI. However, identified loci only explain a small\nproportion of the variation ob-served for this phenotype. The linear nature of\ngenome wide association studies (GWAS) used to identify associations between\ngenetic variants and the phenotype have had limited success in explaining the\nheritability variation of BMI and shown low predictive capacity in\nclassification studies. GWAS ignores the epistatic interactions that less\nsignificant variants have on the phenotypic outcome. In this paper we utilise a\nnovel deep learning-based methodology to reduce the high dimensional space in\nGWAS and find epistatic interactions between SNPs for classification purposes.\nSNPs were filtered based on the effects associations have with BMI. Since\nBonferroni adjustment for multiple testing is highly conservative, an important\nproportion of SNPs involved in SNP-SNP interactions are ignored. Therefore,\nonly SNPs with p-values < 1x10-2 were considered for subsequent epistasis\nanalysis using stacked auto encoders (SAE). This allows the nonlinearity\npresent in SNP-SNP interactions to be discovered through progressively smaller\nhidden layer units and to initialise a multi-layer feedforward artificial\nneural network (ANN) classifier. The classifier is fine-tuned to classify\nextremely obese and non-obese individuals. The best results were obtained with\n2000 compressed units (SE=0.949153, SP=0.933014, Gini=0.949936,\nLo-gloss=0.1956, AUC=0.97497 and MSE=0.054057). Using 50 compressed units it\nwas possible to achieve (SE=0.785311, SP=0.799043, Gini=0.703566,\nLogloss=0.476864, AUC=0.85178 and MSE=0.156315).\n", "pos": 5.259783032855078}
{"text": "Noncommutative hyperbolic metrics\n  We characterize certain noncommutative domains in terms of noncommutative\nholomorphic equivalence via a pseudometric that we define in purely algebraic\nterms. We prove some properties of this pseudometric and provide an application\nto free probability.\n", "pos": 5.148499109239493}
{"text": "Existence of global weak solutions to the kinetic Hookean dumbbell model for incompressible dilute polymeric fluids\n  We explore the existence of global weak solutions to the Hookean dumbbell\nmodel, a system of nonlinear partial differential equations that arises from\nthe kinetic theory of dilute polymers, involving the unsteady incompressible\nNavier--Stokes equations in a bounded domain in two or three space dimensions,\ncoupled to a Fokker--Planck-type parabolic equation. We prove the existence of\nlarge-data global weak solutions in the case of two space dimensions.\nIndirectly, our proof also rigorously demonstrates that, in two space\ndimensions at least, the Oldroyd-B model is the macroscopic closure of the\nHookean dumbbell model. In three space dimensions, we prove the existence of\nlarge-data global weak subsolutions to the model, which are weak solutions with\na defect measure, where the defect measure appearing in the Navier--Stokes\nmomentum equation is the divergence of a symmetric positive semidefinite\nmatrix-valued Radon measure.\n", "pos": 5.352825862375076}
{"text": "Cluster validation by measurement of clustering characteristics relevant to the user\n  There are many cluster analysis methods that can produce quite different\nclusterings on the same dataset. Cluster validation is about the evaluation of\nthe quality of a clustering; \"relative cluster validation\" is about using such\ncriteria to compare clusterings. This can be used to select one of a set of\nclusterings from different methods, or from the same method ran with different\nparameters such as different numbers of clusters.\nThere are many cluster validation indexes in the literature. Most of them\nattempt to measure the overall quality of a clustering by a single number, but\nthis can be inappropriate. There are various different characteristics of a\nclustering that can be relevant in practice, depending on the aim of\nclustering, such as low within-cluster distances and high between-cluster\nseparation.\nIn this paper, a number of validation criteria will be introduced that refer\nto different desirable characteristics of a clustering, and that characterise a\nclustering in a multidimensional way. In specific applications the user may be\ninterested in some of these criteria rather than others. A focus of the paper\nis on methodology to standardise the different characteristics so that users\ncan aggregate them in a suitable way specifying weights for the various\ncriteria that are relevant in the clustering application at hand.\n", "pos": 5.154722826398648}
{"text": "Reflection $K$-matrices for a nineteen vertex model with $U_{q}[\\mathrm{osp}\\left(2|2\\right)^{\\left(2\\right)}]$ symmetry\n  We derive the solutions of the boundary Yang-Baxter equation associated with\na supersymmetric nineteen vertex model constructed from the three-dimensional\nrepresentation of the twisted quantum affine Lie superalgebra\n$U_{q}[\\mathrm{osp}\\left(2|2\\right)^{\\left(2\\right)}]\\simeq\nU_{q}[C\\left(2\\right)^{\\left(2\\right)}]$. We found three classes of solutions.\nThe type I solution is characterized by three boundary free-parameters and all\nelements of the corresponding reflection $K$-matrix are different from zero. In\nthe type II solution, the reflection $K$-matrix is even (every element of the\n$K$-matrix with an odd parity is null) and it has only one boundary\nfree-parameter. Finally, the type III solution corresponds to a diagonal\nreflection $K$-matrix with two boundary free-parameters.\n", "pos": 5.171271614827543}
{"text": "Deep Convolutional Neural Network Inference with Floating-point Weights and Fixed-point Activations\n  Deep convolutional neural network (CNN) inference requires significant amount\nof memory and computation, which limits its deployment on embedded devices. To\nalleviate these problems to some extent, prior research utilize low precision\nfixed-point numbers to represent the CNN weights and activations. However, the\nminimum required data precision of fixed-point weights varies across different\nnetworks and also across different layers of the same network. In this work, we\npropose using floating-point numbers for representing the weights and\nfixed-point numbers for representing the activations. We show that using\nfloating-point representation for weights is more efficient than fixed-point\nrepresentation for the same bit-width and demonstrate it on popular large-scale\nCNNs such as AlexNet, SqueezeNet, GoogLeNet and VGG-16. We also show that such\na representation scheme enables compact hardware multiply-and-accumulate (MAC)\nunit design. Experimental results show that the proposed scheme reduces the\nweight storage by up to 36% and power consumption of the hardware multiplier by\nup to 50%.\n", "pos": 5.49438378441901}
{"text": "The Rational Distance Problem for Equilateral Triangles\n  Let (P) denote the problem of existence of a point in the plane of a given\ntriangle T, that is at rational distance from all the vertices of T. In this\narticle, we provide a complete solution to (P) for all equilateral triangles.\n", "pos": 5.147942688566108}
{"text": "Main and Interaction Effects Selection for Quadratic Discriminant Analysis via Penalized Linear Regression\n  Discriminant analysis is a useful classification method. Variable selection\nfor discriminant analysis is becoming more and more im- portant in a\nhigh-dimensional setting. This paper is concerned with the binary-class\nproblems of main and interaction effects selection for the quadratic\ndiscriminant analysis. We propose a new penalized quadratic discriminant\nanalysis (QDA) for variable selection in binary classification. Under sparsity\nassumption on the relevant variables, we conduct a penalized liner regression\nto derive sparse QDA by plug- ging the main and interaction effects in the\nmodel. Then the QDA problem is converted to a penalized sparse ordinary least\nsquares op- timization by using the composite absolute penalties (CAP). Coor-\ndinate descent algorithm is introduced to solve the convex penalized least\nsquares. The penalized linear regression can simultaneously se- lect the main\nand interaction effects, and also conduct classification. Compared with the\nexisting methods of variable selection in QDA, the extensive simulation studies\nand two real data analyses demon- strate that our proposed method works well\nand is robust in the performance of variable selection and classification.\n", "pos": 5.185948117152305}
{"text": "Orientably-regular maps on twisted linear fractional groups\n  We present an enumeration of orientably-regular maps with automorphism group\nisomorphic to the twisted linear fractional group $M(q^2)$ for any odd prime\npower $q$.\n", "pos": 5.45188503754368}
{"text": "What drives transient behaviour in complex systems?\n  We study transient behaviour in the dynamics of complex systems described by\na set of non-linear ODE's. Destabilizing nature of transient trajectories is\ndiscussed and its connection with the eigenvalue-based linearization procedure.\nThe complexity is realized as a random matrix drawn from a modified May-Wigner\nmodel. Based on the initial response of the system, we identify a novel\nstable-transient regime. We calculate exact abundances of typical and extreme\ntransient trajectories finding both Gaussian and Tracy-Widom distributions\nknown in extreme value statistics. We identify degrees of freedom driving\ntransient behaviour as connected to the eigenvectors and encoded in a\nnon-orthogonality matrix $T_0$. We accordingly extend the May-Wigner model to\ncontain a phase with typical transient trajectories present. An exact norm of\nthe trajectory is obtained in the vanishing $T_0$ limit where it describes a\nnormal matrix.\n", "pos": 5.488473718485799}
{"text": "Learning Texture Manifolds with the Periodic Spatial GAN\n  This paper introduces a novel approach to texture synthesis based on\ngenerative adversarial networks (GAN) (Goodfellow et al., 2014). We extend the\nstructure of the input noise distribution by constructing tensors with\ndifferent types of dimensions. We call this technique Periodic Spatial GAN\n(PSGAN). The PSGAN has several novel abilities which surpass the current state\nof the art in texture synthesis. First, we can learn multiple textures from\ndatasets of one or more complex large images. Second, we show that the image\ngeneration with PSGANs has properties of a texture manifold: we can smoothly\ninterpolate between samples in the structured noise space and generate novel\nsamples, which lie perceptually between the textures of the original dataset.\nIn addition, we can also accurately learn periodical textures. We make multiple\nexperiments which show that PSGANs can flexibly handle diverse texture and\nimage data sources. Our method is highly scalable and it can generate output\nimages of arbitrary large size.\n", "pos": 5.302152119703172}
{"text": "On Machine Learning and Structure for Mobile Robots\n  Due to recent advances - compute, data, models - the role of learning in\nautonomous systems has expanded significantly, rendering new applications\npossible for the first time. While some of the most significant benefits are\nobtained in the perception modules of the software stack, other aspects\ncontinue to rely on known manual procedures based on prior knowledge on\ngeometry, dynamics, kinematics etc. Nonetheless, learning gains relevance in\nthese modules when data collection and curation become easier than manual rule\ndesign. Building on this coarse and broad survey of current research, the final\nsections aim to provide insights into future potentials and challenges as well\nas the necessity of structure in current practical applications.\n", "pos": 5.591976603589106}
{"text": "Convex Geometry of the Generalized Matrix-Fractional Function\n  Generalized matrix-fractional (GMF) functions are a class of matrix support\nfunctions introduced by Burke and Hoheisel as a tool for unifying a range of\nseemingly divergent matrix optimization problems associated with inverse\nproblems, regularization and learning. In this paper we dramatically simplify\nthe support function representation for GMF functions as well as the\nrepresentation of their subdifferentials. These new representations allow the\nready computation of a range of important related geometric objects whose\nformulations were previously unavailable.\n", "pos": 5.15756580386209}
{"text": "Techniques in Lattice Basis Reduction\n  The credit on {\\it reduction theory} goes back to the work of Lagrange,\nGauss, Hermite, Korkin, Zolotarev, and Minkowski. Modern reduction theory is\nvoluminous and includes the work of A. Lenstra, H. Lenstra and L. Lovasz who\ncreated the well known LLL algorithm, and many other researchers such as L.\nBabai and C. P. Schnorr who created significant new variants of basis reduction\nalgorithms. In this paper, we propose and investigate the efficacy of new\noptimization techniques to be used along with LLL algorithm. The techniques we\nhave proposed are: i) {\\it hill climbing (HC)}, ii) {\\it lattice diffusion-sub\nlattice fusion (LDSF)}, and iii) {\\it multistage hybrid LDSF-HC}. The first\ntechnique relies on the sensitivity of LLL to permutations of the input basis\n$B$, and optimization ideas over the symmetric group $S_m$ viewed as a metric\nspace. The second technique relies on partitioning the lattice into\nsublattices, performing basis reduction in the partition sublattice blocks,\nfusing the sublattices, and repeating. We also point out places where parallel\ncomputation can reduce run-times achieving almost linear speedup. The\nmultistage hybrid technique relies on the lattice diffusion and sublattice\nfusion and hill climbing algorithms.\n", "pos": 5.519168874929546}
{"text": "Fulde-Ferrell-Larkin-Ovchinnikov state in spin-orbit-coupled superconductors\n  We show that in the presence of magnetic field, two superconducting phases\nwith the center-of-mass momentum of Cooper pair parallel to the magnetic field\nare induced in spin-orbit-coupled superconductor Li$_2$Pd$_3$B. Specifically,\nat small magnetic field, the center-of-mass momentum is induced due to the\nenergy-spectrum distortion and no unpairing region with vanishing singlet\ncorrelation appears. We refer to this superconducting state as the drift-BCS\nstate. By further increasing the magnetic field, the superconducting state\nfalls into the Fulde-Ferrell-Larkin-Ovchinnikov state with the emergence of the\nunpairing regions. The observed abrupt enhancement of the center-of-mass\nmomenta and suppression on the order parameters during the crossover indicate\nthe first-order phase transition. Enhanced Pauli limit and hence enlarged\nmagnetic-field regime of the Fulde-Ferrell-Larkin-Ovchinnikov state, due to the\nspin-flip terms of the spin-orbit coupling, are revealed. We also address the\ntriplet correlations induced by the spin-orbit coupling, and show that the\nCooper-pair spin polarizations, generated by the magnetic field and\ncenter-of-mass momentum with the triplet correlations, exhibit totally\ndifferent magnetic-field dependences between the drift-BCS and\nFulde-Ferrell-Larkin-Ovchinnikov states.\n", "pos": 5.332757078883036}
{"text": "Wirtinger systems of generators of knot groups\n  We define the {\\it Wirtinger number} of a link, an invariant closely related\nto the meridional rank. The Wirtinger number is the minimum number of\ngenerators of the fundamental group of the link complement over all meridional\npresentations in which every relation is an iterated Wirtinger relation arising\nin a diagram. We prove that the Wirtinger number of a link equals its bridge\nnumber. This equality can be viewed as establishing a weak version of Cappell\nand Shaneson's Meridional Rank Conjecture, and suggests a new approach to this\nconjecture. Our result also leads to a combinatorial technique for obtaining\nstrong upper bounds on bridge numbers. This technique has so far allowed us to\nadd the bridge numbers of approximately 50,000 prime knots of up to 14\ncrossings to the knot table. As another application, we use the Wirtinger\nnumber to show there exists a universal constant $C$ with the property that the\nhyperbolic volume of a prime alternating link $L$ is bounded below by $C$ times\nthe bridge number of $L$.\n", "pos": 5.383957847129574}
{"text": "Information Theoretic Limits for Linear Prediction with Graph-Structured Sparsity\n  We analyze the necessary number of samples for sparse vector recovery in a\nnoisy linear prediction setup. This model includes problems such as linear\nregression and classification. We focus on structured graph models. In\nparticular, we prove that sufficient number of samples for the weighted graph\nmodel proposed by Hegde and others is also necessary. We use the Fano's\ninequality on well constructed ensembles as our main tool in establishing\ninformation theoretic lower bounds.\n", "pos": 5.516062574849016}
{"text": "Frequency measurement of the clock transition of an indium ion sympathetically-cooled in a linear trap\n  We report frequency measurement of the clock transition in an 115In+ ion\nsympathetically-cooled with Ca+ ions in a linear rf trap. The Ca+ ions are used\nas a probe of the external electromagnetic field and as the coolant for\npreparing the cold In+. The frequency is determined to be 1 267 402 452 901\n049.9 (6.9) Hz by averaging 36 measurements using an optical frequency comb\nreferenced to the frequency standards located in the same site.\n", "pos": 5.263618947671823}
{"text": "On Preserving Observation Properties of the Reduced Supervisor in Discrete-Event Systems\n  Supervisor reduction procedure can be used to construct the reduced\nsupervisor with a reduced number of states in discrete-event systems. The main\nconcepts which are used in this procedure are control consistency of states,\ncontrol cover, induced supervisor, and normality of the reduced supervisor\nw.r.t. the original supervisor. In this paper, it is proved that the reduced\nsupervisor, constructed by the proposed method in [9], preserves the\nobservation properties, i.e. normality and relative observability, by self\nlooping corresponding unobservable events at some states of the reduced\nsupervisor. This property can be applied to find a natural projection, under\nwhich the supervisor is relative observable.\n", "pos": 5.374770425238202}
{"text": "An Inexact Newton-like conditional gradient method for constrained nonlinear systems\n  In this paper, we propose an inexact Newton-like conditional gradient method\nfor solving constrained systems of nonlinear equations. The local convergence\nof the new method as well as results on its rate are established by using a\ngeneral majorant condition. Two applications of such condition are provided:\none is for functions whose the derivative satisfies Holder-like condition and\nthe other is for functions that satisfies a Smale condition, which includes a\nsubstantial class of analytic functions. Some preliminaries numerical\nexperiments illustrating the applicability of the proposed method for medium\nand large problems are also presented.\n", "pos": 5.25934477600186}
{"text": "Beyond conventional photon-number detection with click detectors\n  Photon-number measurements are a fundamental technique for the discrimination\nand characterization of quantum states of light. Beyond the abilities of\nstate-of-the-art devices, we present measurements with an array of 100\navalanche photodiodes exposed to photon-numbers ranging from well below to\nsignificantly above one photon per diode. Despite each single diode only\ndiscriminating between zero and non-zero photon-numbers we are able to extract\ncharacteristic information about the quantum state. We demonstrate a vast\nenhancement of the applicable intensity range by two orders of magnitude\nrelative to the standard application of such devices. It turns out that the\nprobabilistic mapping of arbitrary photon-numbers on a finite number of\nregistered clicks is not per se a disadvantage compared with true photon\ncounters. Such detector arrays can bridge the gap between single-photon and\nlinear detection, by directly using the recorded data, without the need of\nelaborate data reconstruction methods.\n", "pos": 5.1658901120141145}
{"text": "Coordinating Collaborative Chat in Massive Open Online Courses\n  An earlier study of a collaborative chat intervention in a Massive Open\nOnline Course (MOOC) identified negative effects on attrition stemming from a\nrequirement for students to be matched with exactly one partner prior to\nbeginning the activity. That study raised questions about how to orchestrate a\ncollaborative chat intervention in a MOOC context in order to provide the\nbenefit of synchronous social engagement without the coordination difficulties.\nIn this paper we present a careful analysis of an intervention designed to\novercome coordination difficulties by welcoming students into the chat on a\nrolling basis as they arrive rather than requiring them to be matched with a\npartner before beginning. The results suggest the most positive impact when\nexperiencing a chat with exactly one partner rather than more or less. A\nqualitative analysis of the chat data reveals differential experiences between\nthese configurations that suggests a potential explanation for the effect and\nraises questions for future research.\n", "pos": 5.345431570414091}
{"text": "3D Simulation of Electron and Ion Transmission of GEM-based Detectors\n  Time Projection Chamber (TPC) has been chosen as the main tracking system in\nseveral high-flux and high repetition rate experiments. These include on-going\nexperiments such as ALICE and future experiments such as PANDA at FAIR and ILC.\nDifferent $\\mathrm{R}\\&\\mathrm{D}$ activities were carried out on the adoption\nof Gas Electron Multiplier (GEM) as the gas amplification stage of the\nALICE-TPC upgrade version. The requirement of low ion feedback has been\nestablished through these activities. Low ion feedback minimizes distortions\ndue to space charge and maintains the necessary values of detector gain and\nenergy resolution. In the present work, Garfield simulation framework has been\nused to study the related physical processes occurring within single, triple\nand quadruple GEM detectors. Ion backflow and electron transmission of\nquadruple GEMs, made up of foils with different hole pitch under different\nelectromagnetic field configurations (the projected solutions for the ALICE\nTPC) have been studied. Finally a new triple GEM detector configuration with\nlow ion backflow fraction and good electron transmission properties has been\nproposed as a simpler GEM-based alternative suitable for TPCs for future\ncollider experiments.\n", "pos": 5.611783198073483}
{"text": "Deep Relaxation: partial differential equations for optimizing deep neural networks\n  In this paper we establish a connection between non-convex optimization\nmethods for training deep neural networks and nonlinear partial differential\nequations (PDEs). Relaxation techniques arising in statistical physics which\nhave already been used successfully in this context are reinterpreted as\nsolutions of a viscous Hamilton-Jacobi PDE. Using a stochastic control\ninterpretation allows we prove that the modified algorithm performs better in\nexpectation that stochastic gradient descent. Well-known PDE regularity results\nallow us to analyze the geometry of the relaxed energy landscape, confirming\nempirical evidence. The PDE is derived from a stochastic homogenization\nproblem, which arises in the implementation of the algorithm. The algorithms\nscale well in practice and can effectively tackle the high dimensionality of\nmodern neural networks.\n", "pos": 5.5415955217199215}
{"text": "A General Approximation Method for Bicriteria Minimization Problems\n  We present a general technique for approximating bicriteria minimization\nproblems with positive-valued, polynomially computable objective functions.\nGiven $0<\\epsilon\\leq1$ and a polynomial-time $\\alpha$-approximation algorithm\nfor the corresponding weighted sum problem, we show how to obtain a bicriteria\n$(\\alpha\\cdot(1+2\\epsilon),\\alpha\\cdot(1+\\frac{2}{\\epsilon}))$-approximation\nalgorithm for the budget-constrained problem whose running time is polynomial\nin the encoding length of the input and linear in $\\frac{1}{\\epsilon}$.\nMoreover, we show that our method can be extended to compute an\n$(\\alpha\\cdot(1+2\\epsilon),\\alpha\\cdot(1+\\frac{2}{\\epsilon}))$-approximate\nPareto curve under the same assumptions. Our technique applies to many\nminimization problems to which most previous algorithms for computing\napproximate Pareto curves cannot be applied because the corresponding gap\nproblem is $\\textsf{NP}$-hard to solve. For maximization problems, however, we\nshow that approximation results similar to the ones presented here for\nminimization problems are impossible to obtain in polynomial time unless\n$\\textsf{P}=\\textsf{NP}$.\n", "pos": 5.520416705699326}
{"text": "An Orchestrated Empirical Study on Deep Learning Frameworks and Platforms\n  Deep learning (DL) has recently achieved tremendous success in a variety of\ncutting-edge applications, e.g., image recognition, speech and natural language\nprocessing, and autonomous driving. Besides the available big data and hardware\nevolution, DL frameworks and platforms play a key role to catalyze the\nresearch, development, and deployment of DL intelligent solutions. However, the\ndifference in computation paradigm, architecture design and implementation of\nexisting DL frameworks and platforms brings challenges for DL software\ndevelopment, deployment, maintenance, and migration. Up to the present, it\nstill lacks a comprehensive study on how current diverse DL frameworks and\nplatforms influence the DL software development process.\nIn this paper, we initiate the first step towards the investigation on how\nexisting state-of-the-art DL frameworks (i.e., TensorFlow, Theano, and Torch)\nand platforms (i.e., server/desktop, web, and mobile) support the DL software\ndevelopment activities. We perform an in-depth and comparative evaluation on\nmetrics such as learning accuracy, DL model size, robustness, and performance,\non state-of-the-art DL frameworks across platforms using two popular datasets\nMNIST and CIFAR-10. Our study reveals that existing DL frameworks still suffer\nfrom compatibility issues, which becomes even more severe when it comes to\ndifferent platforms. We pinpoint the current challenges and opportunities\ntowards developing high quality and compatible DL systems. To ignite further\ninvestigation along this direction to address urgent industrial demands of\nintelligent solutions, we make all of our assembled feasible toolchain and\ndataset publicly available.\n", "pos": 5.294854251214476}
{"text": "Predicting readmission risk from doctors' notes\n  We develop a model using deep learning techniques and natural language\nprocessing on unstructured text from medical records to predict hospital-wide\n$30$-day unplanned readmission, with c-statistic $.70$. Our model is\nconstructed to allow physicians to interpret the significant features for\nprediction.\n", "pos": 5.565093263668496}
{"text": "Experimental constraints on the rheology, eruption and emplacement dynamics of analog lavas comparable to Mercury's northern volcanic plains\n  We present new viscosity measurements of a synthetic silicate system\nconsidered an analogue for the lava erupted on the surface of Mercury. In\nparticular, we focus on the northern volcanic plains (NVP), which correspond to\nthe largest lava flows on Mercury and possibly in the Solar System.\nHigh-temperature viscosity measurements were performed at both superliquidus\n(up to 1736 K) and subliquidus conditions (1569-1502 K) to constrain the\nviscosity variations as a function of crystallinity (from 0 to 28\\%) and shear\nrate (from 0.1 to 5 s 1). Melt viscosity shows moderate variations (4-16 Pa s)\nin the temperature range of 1736-1600 K. Experiments performed below the\nliquidus temperature show an increase in viscosity as shear rate decreases from\n5 to 0.1 s 1, resulting in a shear thinning behavior, with a decrease in\nviscosity of 1 log unit. The low viscosity of the studied composition may\nexplain the ability of NVP lavas to cover long distances, on the order of\nhundreds of kilometers in a turbulent flow regime. Using our experimental data\nwe estimate that lava flows with thickness of 1, 5, and 10 m are likely to have\nvelocities of 4.8, 6.5, and 7.2 m/s, respectively, on a 5 degree ground slope.\nNumerical modeling incorporating both the heat loss of the lavas and its\npossible crystallization during emplacement allows us to infer that high\neffusion rates (>10,000 m3/s) are necessary to cover the large distances\nindicated by satellite data from the MErcury Surface, Space ENvironment,\nGEochemistry, and Ranging spacecraft.\n", "pos": 5.634019829053534}
{"text": "Universal Absence of Walker Breakdown and Linear Current-Velocity Relation via Spin-Orbit Torques in Coupled and Single Domain Wall Motion\n  We consider theoretically domain wall motion driven by spin-orbit and spin\nHall torques. We find that it is possible to achieve universal absence of\nWalker breakdown for all spin-orbit torques using experimentally relevant\nspin-orbit coupling strengths. For spin-orbit torques other than the pure\nRashba spin-orbit torque, this gives a linear current-velocity relation instead\nof a saturation of the velocity at high current densities. The effect is very\nrobust and is found in both soft and hard magnetic materials, as well as in the\npresence of the Dzyaloshinskii-Moriya interaction and in coupled domain walls\nin synthetic antiferromagnets, where it leads to very high domain wall\nvelocities. Moreover, recent experiments have demonstrated that the switching\nof a synthetic antiferromagnet does not obey the usual spin Hall\nangle-dependence, but that domain expansion and contraction can be selectively\ncontrolled toggling only the applied in-plane magnetic field magnitude and not\nits sign. We show for the first time that the combination of spin Hall torques\nand interlayer exchange coupling produces the necessary relative velocities for\nthis switching to occur.\n", "pos": 5.401118016141037}
{"text": "Symbolic dynamics for Kuramoto-Sivashinsky PDE on the line --- a computer-assisted proof\n  The Kuramoto-Sivashinsky PDE on the line with odd and periodic boundary\nconditions and with parameter $\\nu=0.1212$ is considered. We give a\ncomputer-assisted proof the existence of symbolic dynamics and countable\ninfinity of periodic orbits with arbitrary large periods.\n", "pos": 5.352098919485462}
{"text": "Tractable and Scalable Schatten Quasi-Norm Approximations for Rank Minimization\n  The Schatten quasi-norm was introduced to bridge the gap between the trace\nnorm and rank function. However, existing algorithms are too slow or even\nimpractical for large-scale problems. Motivated by the equivalence relation\nbetween the trace norm and its bilinear spectral penalty, we define two\ntractable Schatten norms, i.e.\\ the bi-trace and tri-trace norms, and prove\nthat they are in essence the Schatten-$1/2$ and $1/3$ quasi-norms,\nrespectively. By applying the two defined Schatten quasi-norms to various rank\nminimization problems such as MC and RPCA, we only need to solve much smaller\nfactor matrices. We design two efficient linearized alternating minimization\nalgorithms to solve our problems and establish that each bounded sequence\ngenerated by our algorithms converges to a critical point. We also provide the\nrestricted strong convexity (RSC) based and MC error bounds for our algorithms.\nOur experimental results verified both the efficiency and effectiveness of our\nalgorithms compared with the state-of-the-art methods.\n", "pos": 5.608408210930915}
{"text": "Deformation estimation of an elastic object by partial observation using a neural network\n  Deformation estimation of elastic object assuming an internal organ is\nimportant for the computer navigation of surgery. The aim of this study is to\nestimate the deformation of an entire three-dimensional elastic object using\ndisplacement information of very few observation points. A learning approach\nwith a neural network was introduced to estimate the entire deformation of an\nobject. We applied our method to two elastic objects; a rectangular\nparallelepiped model, and a human liver model reconstructed from computed\ntomography data. The average estimation error for the human liver model was\n0.041 mm when the object was deformed up to 66.4 mm, from only around 3 %\nobservations. These results indicate that the deformation of an entire elastic\nobject can be estimated with an acceptable level of error from limited\nobservations by applying a trained neural network to a new deformation.\n", "pos": 5.557932114671083}
{"text": "Consistent Inter-Model Specification for Time-Homogeneous SPX Stochastic Volatility and VIX Market Models\n  This paper shows how to recover stochastic volatility models (SVMs) from\nmarket models for the VIX futures term structure. Market models have more\nflexibility for fitting of curves than do SVMs, and therefore they are\nbetter-suited for pricing VIX futures and derivatives. But the VIX itself is a\nderivative of the S&P500 (SPX) and it is common practice to price SPX\nderivatives using an SVM. Hence, a consistent model for both SPX and VIX\nderivatives would be one where the SVM is obtained by inverting the market\nmodel. This paper's main result is a method for the recovery of a stochastic\nvolatility function as the output of an inverse problem, with the inputs given\nby a VIX futures market model. Analysis will show that some conditions need to\nbe met in order for there to not be any inter-model arbitrage or mis-priced\nderivatives. Given these conditions the inverse problem can be solved. Several\nmodels are analyzed and explored numerically to gain a better understanding of\nthe theory and its limitations.\n", "pos": 5.658168712924654}
{"text": "A cost effective and reliable environment monitoring system for HPC applications\n  We present a slow control system to gather all relevant environment\ninformation necessary to effectively and reliably run an HPC (High Performance\nComputing) system at a high value over price ratio. The scalable and reliable\noverall concept is presented as well as a newly developed hardware device for\nsensor read out. This device incorporates a Raspberry Pi, an Arduino and PoE\n(Power over Ethernet) functionality in a compact form factor. The system is in\nuse at the 2 PFLOPS cluster of the Johannes Gutenberg-University and\nHelmholtz-Institute in Mainz.\n", "pos": 5.24981219070271}
{"text": "A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning\n  Automatic decision-making approaches, such as reinforcement learning (RL),\nhave been applied to (partially) solve the resource allocation problem\nadaptively in the cloud computing system. However, a complete cloud resource\nallocation framework exhibits high dimensions in state and action spaces, which\nprohibit the usefulness of traditional RL techniques. In addition, high power\nconsumption has become one of the critical concerns in design and control of\ncloud computing systems, which degrades system reliability and increases\ncooling cost. An effective dynamic power management (DPM) policy should\nminimize power consumption while maintaining performance degradation within an\nacceptable level. Thus, a joint virtual machine (VM) resource allocation and\npower management framework is critical to the overall cloud computing system.\nMoreover, novel solution framework is necessary to address the even higher\ndimensions in state and action spaces. In this paper, we propose a novel\nhierarchical framework for solving the overall resource allocation and power\nmanagement problem in cloud computing systems. The proposed hierarchical\nframework comprises a global tier for VM resource allocation to the servers and\na local tier for distributed power management of local servers. The emerging\ndeep reinforcement learning (DRL) technique, which can deal with complicated\ncontrol problems with large state space, is adopted to solve the global tier\nproblem. Furthermore, an autoencoder and a novel weight sharing structure are\nadopted to handle the high-dimensional state space and accelerate the\nconvergence speed. On the other hand, the local tier of distributed server\npower managements comprises an LSTM based workload predictor and a model-free\nRL based power manager, operating in a distributed manner.\n", "pos": 5.570595768534224}
{"text": "Quantum Harmonic Analysis of the Density Matrix: Basics\n  In this Review we will study rigorously the notion of mixed states and their\ndensity matrices. We mostly give complete proofs. We will also discuss the\nquantum-mechanical consequences of possible variations of Planck's constant h.\nThis Review has been written having in mind two readerships: mathematical\nphysicists and quantum physicists. The mathematical rigor is maximal, but the\nlanguage and notation we use throughout should be familiar to physicists.\n", "pos": 5.178826792004831}
{"text": "A Convex Similarity Index for Sparse Recovery of Missing Image Samples\n  This paper investigates the problem of recovering missing samples using\nmethods based on sparse representation adapted especially for image signals.\nInstead of $l_2$-norm or Mean Square Error (MSE), a new perceptual quality\nmeasure is used as the similarity criterion between the original and the\nreconstructed images. The proposed criterion called Convex SIMilarity (CSIM)\nindex is a modified version of the Structural SIMilarity (SSIM) index, which\ndespite its predecessor, is convex and uni-modal. We derive mathematical\nproperties for the proposed index and show how to optimally choose the\nparameters of the proposed criterion, investigating the Restricted Isometry\n(RIP) and error-sensitivity properties. We also propose an iterative sparse\nrecovery method based on a constrained $l_1$-norm minimization problem,\nincorporating CSIM as the fidelity criterion. The resulting convex optimization\nproblem is solved via an algorithm based on Alternating Direction Method of\nMultipliers (ADMM). Taking advantage of the convexity of the CSIM index, we\nalso prove the convergence of the algorithm to the globally optimal solution of\nthe proposed optimization problem, starting from any arbitrary point.\nSimulation results confirm the performance of the new similarity index as well\nas the proposed algorithm for missing sample recovery of image patch signals.\n", "pos": 5.420137926296338}
{"text": "Strain Mode of General Flow: Characterization and Implications for Flow Pattern Structures\n  Understanding the mixing capability of mixing devices based on their\ngeometric shape is an important issue both for predicting mixing processes and\nfor designing new mixers. The flow patterns in mixers are directly connected\nwith the modes of the local strain rate, which is generally a combination of\nelongational flow and planar shear flow. We develop a measure to characterize\nthe modes of the strain rate for general flow occurring in mixers. The spatial\ndistribution of the volumetric strain rate (or non-planar strain rate) in\nconnection with the flow pattern plays an essential role in understanding\ndistributive mixing. With our measure, flows with different types of screw\nelements in a twin-screw extruder are numerically analyzed. The difference in\nflow pattern structure between conveying screws and kneading disks is\nsuccessfully characterized by the distribution of the volumetric strain rate.\nThe results suggest that the distribution of the strain rate mode offers an\nessential and convenient way for characterization of the relation between flow\npattern structure and the mixer geometry.\n", "pos": 5.425457644073937}
{"text": "Large global-in-time solutions to a nonlocal model of chemotaxis\n  We consider the parabolic-elliptic model for the chemotaxis with fractional\n(anomalous) diffusion. Global-in-time solutions are constructed under (nearly)\noptimal assumptions on the size of radial initial data. Moreover, criteria for\nblowup of radial solutions in terms of suitable Morrey spaces norms are\nderived.\n", "pos": 5.232596941652664}
{"text": "A class of states supporting diffusive spin dynamics in the isotropic Heisenberg model\n  The spin transport in isotropic Heisenberg model in the sector with zero\nmagnetization is generically super-diffusive. Despite that, we here demonstrate\nthat for a specific set of domain-wall-like initial product states it can\ninstead be diffusive. We theoretically explain the time evolution of such\nstates by showing that in the limiting regime of weak spatial modulation they\nare approximately product states for very long times, and demonstrate that even\nin the case of larger spatial modulation the bipartite entanglement entropy\ngrows only logarithmically in time. In the limiting regime we derive a simple\nclosed equation governing the dynamics, which in the continuum limit and for\nthe initial step magnetization profile results in a solution expressed in terms\nof Fresnel integrals.\n", "pos": 5.1578669394541325}
{"text": "Henkin constructions of models with size continuum\n  We survey the technique of constructing customized models of size continuum\nin omega steps and illustrate the method by giving new proofs of mostly old\nresults within this rubric. One new theorem, which is joint with Saharon\nShelah, is that a pseudominimal theory has an atomic model of size continuum.\n", "pos": 5.108152259732582}
{"text": "Constant Size Molecular Descriptors For Use With Machine Learning\n  A set of molecular descriptors whose length is independent of molecular size\nis developed for machine learning models that target thermodynamic and\nelectronic properties of molecules. These features are evaluated by monitoring\nperformance of kernel ridge regression models on well-studied data sets of\nsmall organic molecules. The features include connectivity counts, which\nrequire only the bonding pattern of the molecule, and encoded distances, which\nsummarize distances between both bonded and non-bonded atoms and so require the\nfull molecular geometry. In addition to having constant size, these features\nsummarize information regarding the local environment of atoms and bonds, such\nthat models can take advantage of similarities resulting from the presence of\nsimilar chemical fragments across molecules. Combining these two types of\nfeatures leads to models whose performance is comparable to or better than the\ncurrent state of the art. The features introduced here have the advantage of\nleading to models that may be trained on smaller molecules and then used\nsuccessfully on larger molecules.\n", "pos": 5.634702001447599}
{"text": "Preferential placement for community structure formation\n  Various models have been recently proposed to reflect and predict different\nproperties of complex networks. However, the community structure, which is one\nof the most important properties, is not well studied and modeled. In this\npaper, we suggest a principle called \"preferential placement\", which allows to\nmodel a realistic clustering structure. We provide an extensive empirical\nanalysis of the obtained structure as well as some theoretical results.\n", "pos": 5.559317912382917}
{"text": "HPDedup: A Hybrid Prioritized Data Deduplication Mechanism for Primary Storage in the Cloud\n  Eliminating duplicate data in primary storage of clouds increases the\ncost-efficiency of cloud service providers as well as reduces the cost of users\nfor using cloud services. Existing primary deduplication techniques either use\ninline caching to exploit locality in primary workloads or use post-processing\ndeduplication running in system idle time to avoid the negative impact on I/O\nperformance. However, neither of them works well in the cloud servers running\nmultiple services or applications for the following two reasons: Firstly, the\ntemporal locality of duplicate data writes may not exist in some primary\nstorage workloads thus inline caching often fails to achieve good deduplication\nratio. Secondly, the post-processing deduplication allows duplicate data to be\nwritten into disks, therefore does not provide the benefit of I/O deduplication\nand requires high peak storage capacity. This paper presents HPDedup, a Hybrid\nPrioritized data Deduplication mechanism to deal with the storage system shared\nby applications running in co-located virtual machines or containers by fusing\nan inline and a post-processing process for exact deduplication. In the inline\ndeduplication phase, HPDedup gives a fingerprint caching mechanism that\nestimates the temporal locality of duplicates in data streams from different\nVMs or applications and prioritizes the cache allocation for these streams\nbased on the estimation. HPDedup also allows different deduplication threshold\nfor streams based on their spatial locality to reduce the disk fragmentation.\nThe post-processing phase removes duplicates whose fingerprints are not able to\nbe cached due to the weak temporal locality from disks. Our experimental\nresults show that HPDedup clearly outperforms the state-of-the-art primary\nstorage deduplication techniques in terms of inline cache efficiency and\nprimary deduplication efficiency.\n", "pos": 5.565720639367085}
{"text": "The Principle of Similitude in Biology: From Allometry to the Formulation of Dimensionally Homogenous `Laws'\n  Meaningful laws of nature must be independent of the units employed to\nmeasure the variables. The principle of similitude (Rayleigh 1915) or\ndimensional homogeneity, states that only commensurable quantities (ones having\nthe same dimension) may be compared, therefore, meaningful laws of nature must\nbe homogeneous equations in their various units of measurement, a result which\nwas formalized in the $\\rm \\Pi$ theorem (Vaschy 1892; Buckingham 1914).\nHowever, most relations in allometry do not satisfy this basic requirement,\nincluding the `3/4 Law' (Kleiber 1932) that relates the basal metabolic rate\nand body mass, which it is sometimes claimed to be the most fundamental\nbiological rate (Brown et al. 2004) and the closest to a law in life sciences\n(West \\& Brown 2004). Using the $\\rm \\Pi$ theorem, here we show that it is\npossible to construct a unique homogeneous equation for the metabolic rates, in\nagreement with data in the literature. We find that the variations in the\ndependence of the metabolic rates on body mass are secondary, coming from\nvariations in the allometric dependence of the heart frequencies. This includes\nnot only different classes of animals (mammals, birds, invertebrates) but also\ndifferent exercise conditions (basal and maximal). Our results demonstrate that\nmost of the differences found in the allometric exponents (White et al. 2007)\nare due to compare incommensurable quantities and that our dimensionally\nhomogenous formula, unify these differences into a single formulation. We\ndiscuss the ecological implications of this new formulation in the context of\nthe Malthusian's, Fenchel's and the total energy consumed in a lifespan\nrelations.\n", "pos": 5.574573783880162}
{"text": "Quantifying the Contributions of Training Data and Algorithm Logic to the Performance of Automated Cause-assignment Algorithms for Verbal Autopsy\n  A verbal autopsy (VA) consists of a survey with a relative or close contact\nof a person who has recently died. VA surveys are commonly used to infer likely\ncauses of death for individuals when deaths happen outside of hospitals or\nhealthcare facilities. Several statistical and algorithmic methods are\navailable to assign cause of death using VA surveys. Each of these methods\nrequire as inputs some information about the joint distribution of symptoms and\ncauses. In this note, we examine the generalizability of this symptom-cause\ninformation by comparing different automated coding methods using various\ncombinations of inputs and evaluation data. VA algorithm performance is\naffected by both the specific SCI themselves and the logic of a given\nalgorithm. Using a variety of performance metrics for all existing VA\nalgorithms, we demonstrate that in general the adequacy of the information\nabout the joint distribution between symptoms and cause affects performance at\nleast as much or more than algorithm logic.\n", "pos": 5.649490003170898}
{"text": "The evolution of gravitons in accelerating cosmologies: the case of extended gravity\n  We discuss the production and evolution of cosmological gravitons showing how\nthe cosmological background affects their dynamics. Besides, the detection of\ncosmological gravitons could constitute an extremely important signature to\ndiscriminate among different cosmological models. Here we consider the cases of\nscalar-tensor gravity and $f(R)$ gravity where it is demonstrated the\namplification of graviton amplitude changes if compared with General\nRelativity. Possible observational constraints are discussed.\n", "pos": 5.26469690675548}
{"text": "Representation Theorems for Solvable Sesquilinear Forms\n  New results are added to the paper [4] about q-closed and solvable\nsesquilinear forms. The structure of the Banach space\n$\\mathcal{D}[||\\cdot||_\\Omega]$ defined on the domain $\\mathcal{D}$ of a\nq-closed sesquilinear form $\\Omega$ is unique up to isomorphism, and the\nadjoint of a sesquilinear form has the same property of q-closure or of\nsolvability. The operator associated to a solvable sesquilinear form is the\ngreatest which represents the form and it is self-adjoint if, and only if, the\nform is symmetric. We give more criteria of solvability for q-closed\nsesquilinear forms. Some of these criteria are related to the numerical range,\nand we analyse in particular the forms which are solvable with respect to inner\nproducts. The theory of solvable sesquilinear forms generalises those of many\nknown sesquilinear forms in literature.\n", "pos": 5.210416745769837}
{"text": "On Nested Diversities and Novel Correlation-Based Entropies\n  Essential defining characteristics of diversity include the number of\ncategories involved, evenness of the element distribution among categories, and\ndissimilarity between categories. In addition, there are two intrinsic factors\nthat also influence the quantification of diversity. These are how much weight\nto place on the category prevalence, and how much weight to place on the\nbetween-category dissimilarities. In Part I of this paper, we provide a unified\nframework for measuring, comparing and partitioning diversity that incorporates\nall of these aspects. A new principle called the Nesting Principle is\nestablished, stating that diversity remains invariant under arbitrary nesting\nor partitioning of the constituent categories or individual elements. An\nimportant consequence of this principle is that the weight on the category\nprevalence must be set such that the diversity function depends quadratically\non the relative abundances of categories, while the other weight on the\nbetween-category dissimilarity can be adjusted independently and continuously.\nThe resulting diversity index has a unique interpretation in terms of a certain\ncorrelation sum defined within the assemblage whose diversity is to be\nmeasured. The formula for the effective dissimilarity between two arbitrary\nassemblages is also provided, which takes the form of a cross-correlation sum,\nand is compatible with the Nesting Principle. Classic entropy measures of Renyi\nand Tsallis are also generalised to incorporate the dependence on correlations\namong the constituents. In Part II, we discuss applications of the\ncorrelation-based, nesting-invariant entropies to specific research contexts.\nSpecifically, the extended Renyi entropy is used to analyse dynamical and\nfractal properties of a chaotic attractor system. Further, implications of the\nextended Tsallis entropy on non-extensive statistical physics are explored.\n", "pos": 5.4134795707685095}
{"text": "Phase curves of WASP-33b and HD 149026b and a New Correlation Between Phase Curve Offset and Irradiation Temperature\n  We present new 3.6 and 4.5 $\\mu m$ Spitzer phase curves for the highly\nirradiated hot Jupiter WASP-33b and the unusually dense Saturn-mass planet HD\n149026b. As part of this analysis, we develop a new variant of pixel level\ndecorrelation that is effective at removing intrapixel sensitivity variations\nfor long observations (>10 hours) where the position of the star can vary by a\nsignificant fraction of a pixel. Using this algorithm, we measure eclipse\ndepths, phase amplitudes, and phase offsets for both planets at 3.6 $\\mu m$ and\n4.5 $\\mu m$. We use a simple toy model to show that WASP-33b's phase offset,\nalbedo, and heat recirculation efficiency are largely similar to those of other\nhot Jupiters despite its very high irradiation. On the other hand, our fits for\nHD 149026b prefer a very high albedo and an unusually high recirculation\nefficiency. We also compare our results to predictions from general circulation\nmodels, and find that while neither are a good match to the data, the\ndiscrepancies for HD 149026b are especially large. We speculate that this may\nbe related to its high bulk metallicity, which could lead to enhanced\natmospheric opacities and the formation of reflective cloud layers in localized\nregions of the atmosphere. We then place these two planets in a broader context\nby exploring relationships between the temperatures, albedos, heat transport\nefficiencies, and phase offsets of all planets with published thermal phase\ncurves. We find a striking relationship between phase offset and irradiation\ntemperature--the former drops with increasing temperature until around 3400 K,\nand rises thereafter. Although some aspects of this trend are mirrored in the\ncirculation models, there are notable differences that provide important clues\nfor future modeling efforts.\n", "pos": 5.654501871158883}
{"text": "Point-contact spectroscopy of superconducting YBaCuO single crystals of tetragonal modification\n  The point-contact spectra of tetragonal $\\rm YBa_2Cu_3O_{7-\\delta}$ with\n$T_c=50-60~K$ are studied at various temperatures. The single-electron energy\n($2\\Delta_0/kT_c\\simeq 17$) and its temperature dependence are determined. The\ncharacteristic energies of quasiparticle excitations interacting with\nconduction electrons in this high-$T_c$. superconductor are found to correlate\nwith the characteristic phonon energies. The possibility of a pair gap, which\nincreases with temperature, is revealed near the critical temperature.\n", "pos": 5.141690132783617}
{"text": "Monomial tropical cones for multicriteria optimization\n  We present an algorithm to compute all $n$ nondominated points of a\nmulticriteria discrete optimization problem with $d$ objectives using at most\n$\\mathcal{O}(n^{\\lfloor d/2 \\rfloor})$ scalarizations. The method is similar to\nan algorithm by Klamroth et al. (2015) with the same complexity. As a\ndifference, our method employs a tropical convex hull computation, and it\nexploits a particular kind of duality which is special for the tropical cones\narising. This duality can be seen as a generalization of the Alexander duality\nof monomial ideals.\n", "pos": 5.504494500817366}
{"text": "Understanding and predicting travel time with spatio-temporal features of network traffic flow, weather and incidents\n  Travel time on a route varies substantially by time of day and from day to\nday. It is critical to understand to what extent this variation is correlated\nwith various factors, such as weather, incidents, events or travel demand level\nin the context of dynamic networks. This helps a better decision making for\ninfrastructure planning and real-time traffic operation. We propose a\ndata-driven approach to understand and predict highway travel time using\nspatio-temporal features of those factors, all of which are acquired from\nmultiple data sources. The prediction model holistically selects the most\nrelated features from a high-dimensional feature space by correlation analysis,\nprinciple component analysis and LASSO. We test and compare the performance of\nseveral regression models in predicting travel time 30 min in advance via two\ncase studies: (1) a 6-mile highway corridor of I-270N in D.C. region, and (2) a\n2.3-mile corridor of I-376E in Pittsburgh region. We found that some\nbottlenecks scattered in the network can imply congestion on those corridors at\nleast 30 minutes in advance, including those on the alternative route to the\ncorridors of study. In addition, real-time travel time is statistically related\nto incidents on some specific locations, morning/afternoon travel demand,\nvisibility, precipitation, wind speed/gust and the weather type. All those\nspatio-temporal information together help improve prediction accuracy,\ncomparing to using only speed data. In both case studies, random forest shows\nthe most promise, reaching a root-mean-squared error of 16.6\\% and 17.0\\%\nrespectively in afternoon peak hours for the entire year of 2014.\n", "pos": 5.496237664501216}
{"text": "Geodesics around oscillatons made of exponential scalar field potential\n  Oscillatons are spherically symmetric solutions to the Einstein Klein Gordon\n(EKG) equations for soliton stars made of real time dependent scalar fields.\nThese equations are non singular and satisfy flatness conditions asymptotically\nwith periodic time dependency. In this paper, we investigate the geodesic\nmotion of particles moving around an oscillaton related to a time dependent\nscalar field. Bound orbital is found for these particles under the condition of\nparticular values of angular momentum L and initial radial position. We discuss\nthis topic for an exponential scalar field potential which could be of the\nexponential form with a scalar field and investigate whether the radial\ncoordinates of such particles oscillate in time or not and thereby we could\npredict the corresponding oscillating period as well as amplitude. It is\nnecessary to recall, in general relativity, a geodesic generalizes the notion\nof a straight line to curved space time. Importantly, the world line of a\nparticle free from all external, non gravitational forces, is a particular type\nof geodesic. In other words, a freely moving or falling particle always moves\nalong a geodesic. In general relativity, gravity can be regarded as not a force\nbut a consequence of a curved space time geometry where the source of curvature\nis the stress energy tensor (representing matter, for instance). Thus, for\nexample, the path of a planet orbiting around a star is the projection of a\ngeodesic of the curved 4D space time geometry around the star onto 3D space.\n", "pos": 5.670149171076393}
{"text": "Kernel Robust Bias-Aware Prediction under Covariate Shift\n  Under covariate shift, training (source) data and testing (target) data\ndiffer in input space distribution, but share the same conditional label\ndistribution. This poses a challenging machine learning task. Robust Bias-Aware\n(RBA) prediction provides the conditional label distribution that is robust to\nthe worstcase logarithmic loss for the target distribution while matching\nfeature expectation constraints from the source distribution. However,\nemploying RBA with insufficient feature constraints may result in high\ncertainty predictions for much of the source data, while leaving too much\nuncertainty for target data predictions. To overcome this issue, we extend the\nrepresenter theorem to the RBA setting, enabling minimization of regularized\nexpected target risk by a reweighted kernel expectation under the source\ndistribution. By applying kernel methods, we establish consistency guarantees\nand demonstrate better performance of the RBA classifier than competing methods\non synthetically biased UCI datasets as well as datasets that have natural\ncovariate shift.\n", "pos": 5.455416871278395}
{"text": "The Galaxy's Veil of Excited Hydrogen\n  Many of the baryons in our Galaxy probably lie outside the well known disk\nand bulge components. Despite a wealth of evidence for the presence of some gas\nin galactic halos, including absorption line systems in the spectra of quasars,\nhigh velocity neutral hydrogen clouds in our Galaxy halo, line emitting ionised\nhydrogen originating from galactic winds in nearby starburst galaxies, and the\nX-ray coronas surrounding the most massive galaxies, accounting for the gas in\nthe halo of any galaxy has been observationally challenging primarily because\nof its low density in the expansive halo. The most sensitive measurements come\nfrom detecting absorption by the intervening gas in the spectra of distant\nobjects such as quasars or distant halo stars, but these have typically been\nlimited to a few lines of sight to sufficiently bright objects. Massive\nspectroscopic surveys of millions of objects provide an alternative approach to\nthe problem. Here, we present the first evidence for a widely distributed,\nneutral, excited hydrogen component of the Galaxy's halo. It is observed as the\nslight, (0.779 $\\pm$ 0.006)\\%, absorption of flux near the rest wavelength of\nH$\\alpha$ in the combined spectra of hundreds of thousands of galaxy spectra\nand is ubiquitous in high latitude lines of sight. This observation provides an\navenue to tracing, both spatially and kinematically, the majority of the gas in\nthe halo of our Galaxy.\n", "pos": 5.617613055593638}
{"text": "Detection, Recognition and Tracking of Moving Objects from Real-time Video via Visual Vocabulary Model and Species Inspired PSO\n  In this paper, we address the basic problem of recognizing moving objects in\nvideo images using Visual Vocabulary model and Bag of Words and track our\nobject of interest in the subsequent video frames using species inspired PSO.\nInitially, the shadow free images are obtained by background modelling followed\nby foreground modeling to extract the blobs of our object of interest.\nSubsequently, we train a cubic SVM with human body datasets in accordance with\nour domain of interest for recognition and tracking. During training, using the\nprinciple of Bag of Words we extract necessary features of certain domains and\nobjects for classification. Subsequently, matching these feature sets with\nthose of the extracted object blobs that are obtained by subtracting the shadow\nfree background from the foreground, we detect successfully our object of\ninterest from the test domain. The performance of the classification by cubic\nSVM is satisfactorily represented by confusion matrix and ROC curve reflecting\nthe accuracy of each module. After classification, our object of interest is\ntracked in the test domain using species inspired PSO. By combining the\nadaptive learning tools with the efficient classification of description, we\nachieve optimum accuracy in recognition of the moving objects. We evaluate our\nalgorithm benchmark datasets: iLIDS, VIVID, Walking2, Woman. Comparative\nanalysis of our algorithm against the existing state-of-the-art trackers shows\nvery satisfactory and competitive results.\n", "pos": 5.175204825180044}
{"text": "Finite-time scaling at the Anderson transition for vibrations in solids\n  A model in which a three-dimensional elastic medium is represented by a\nnetwork of identical masses connected by springs of random strengths and\nallowed to vibrate only along a selected axis of the reference frame, exhibits\nan Anderson localization transition. To study this transition, we assume that\nthe dynamical matrix of the network is given by a product of a sparse random\nmatrix with real, independent, Gaussian-distributed non-zero entries and its\ntranspose. A finite-time scaling analysis of system's response to an initial\nexcitation allows us to estimate the critical parameters of the localization\ntransition. The critical exponent is found to be $\\nu = 1.57 \\pm 0.02$ in\nagreement with previous studies of Anderson transition belonging to the\nthree-dimensional orthogonal universality class.\n", "pos": 5.614173290949042}
{"text": "Inertial movements of the iris as the origin of post-saccadic oscillations\n  The use of eye-tracking techniques is becoming rapidly extended because of\nits relevance for acquiring information about cognition and behavior. Recent\nstudies indicate that a correct characterization of the motion of the pupil\ninside the eyeball is needed, because this motion influences the eye-tracking\nresults. In this work we face this problem and we develop a model that\nreproduces several findings of recent experiments on saccadic movements. In\nparticular, the dependence of the amplitude and period of the post saccadic\noscillations on the saccade size, as well as that of the peak velocity. Our\nresults suggest that post saccadic oscillations could obey mainly to inertial\nphenomena experimented by the inner part of the iris when the eyeball rotates.\n", "pos": 5.158007478265599}
{"text": "On $(\u03c3,\u03b4)$-skew McCoy modules\n  Let $(\\sigma,\\delta)$ be a quasi derivation of a ring $R$ and $M_R$ a right\n$R$-module. In this paper, we introduce the notion of $(\\sigma,\\delta)$-skew\nMcCoy modules which extends the notion of McCoy modules and $\\sigma$-skew McCoy\nmodules. This concept can be regarded also as a generalization of\n$(\\sigma,\\delta)$-skew Armendariz modules. Some properties of this concept are\nestablished and some connections between $(\\sigma,\\delta)$-skew McCoyness and\n$(\\sigma,\\delta)$-compatible reduced modules are examined. Also, we study the\nproperty $(\\sigma,\\delta)$-skew McCoy of some skew triangular matrix extensions\n$V_n(M,\\sigma)$, for any nonnegative integer $n\\geq 2$. As a consequence, we\nobtain: (1) $M_R$ is $(\\sigma,\\delta)$-skew McCoy if and only if\n$M[x]/M[x](x^n)$ is $(\\overline{\\sigma},\\overline{\\delta})$-skew McCoy, and (2)\n$M_R$ is $\\sigma$-skew McCoy if and only if $M[x;\\sigma]/M[x;\\sigma](x^n)$ is\n$\\overline{\\sigma}$-skew McCoy.\n", "pos": 5.3120423622188016}
{"text": "The homotopy theory of coalgebras over simplicial comonads\n  We apply the Acyclicity Theorem of Hess, Kerdziorek, Riehl, and Shipley\n(recently corrected by Garner, Kedziorek, and Riehl) to establishing the\nexistence of model category structure on categories of coalgebras over comonads\narising from simplicial adjunctions, under mild conditions on the adjunction\nand the associated comonad. We study three concrete examples of such\nadjunctions where the left adjoint is comonadic and show that in each case the\ncomponent of the derived counit of the comparison adjunction at any fibrant\nobject is an isomorphism, while the component of the derived unit at any\n1-connected object is a weak equivalence. To prove this last result, we explain\nhow to construct explicit fibrant replacements for 1-connected coalgebras in\nthe image of the canonical comparison functor from the Postnikov decompositions\nof their underlying simplicial sets. We also show in one case that the derived\nunit is precisely the Bousfield-Kan completion map.\n", "pos": 5.2507322254189255}
{"text": "An analytic resolution to the competition between Lyman-Werner radiation and metal winds in direct collapse black hole hosts\n  A near pristine atomic cooling halo close to a star forming galaxy offers a\nnatural pathway for forming massive direct collapse black hole (DCBH) seeds\nwhich could be the progenitors of the $z>6$ redshift quasars. The close\nproximity of the haloes enables a sufficient Lyman-Werner flux to effectively\ndissociate H$_2$ in the core of the atomic cooling halo. A mild background may\nalso be required to delay star formation in the atomic cooling halo, often\nattributed to distant background galaxies. In this letter we investigate the\nimpact of metal enrichment from both the background galaxies and the close star\nforming galaxy under extremely unfavourable conditions such as instantaneous\nmetal mixing. We find that within the time window of DCBH formation, the level\nof enrichment never exceeds the critical threshold (Z$_{cr} \\sim 1 \\times\n10^{-5} \\ \\rm Z_{\\odot})$, and attains a maximum metallicity of Z $\\sim 2\n\\times 10^{-6} \\ \\rm Z_{\\odot}$. As the system evolves, the metallicity\neventually exceeds the critical threshold, long after the DCBH has formed.\n", "pos": 5.262326513322056}
{"text": "Coresets for Vector Summarization with Applications to Network Graphs\n  We provide a deterministic data summarization algorithm that approximates the\nmean $\\bar{p}=\\frac{1}{n}\\sum_{p\\in P} p$ of a set $P$ of $n$ vectors in\n$\\REAL^d$, by a weighted mean $\\tilde{p}$ of a \\emph{subset} of $O(1/\\eps)$\nvectors, i.e., independent of both $n$ and $d$. We prove that the squared\nEuclidean distance between $\\bar{p}$ and $\\tilde{p}$ is at most $\\eps$\nmultiplied by the variance of $P$. We use this algorithm to maintain an\napproximated sum of vectors from an unbounded stream, using memory that is\nindependent of $d$, and logarithmic in the $n$ vectors seen so far. Our main\napplication is to extract and represent in a compact way friend groups and\nactivity summaries of users from underlying data exchanges. For example, in the\ncase of mobile networks, we can use GPS traces to identify meetings, in the\ncase of social networks, we can use information exchange to identify friend\ngroups. Our algorithm provably identifies the {\\it Heavy Hitter} entries in a\nproximity (adjacency) matrix. The Heavy Hitters can be used to extract and\nrepresent in a compact way friend groups and activity summaries of users from\nunderlying data exchanges. We evaluate the algorithm on several large data\nsets.\n", "pos": 5.280905975862667}
{"text": "The cooling-off effect of price limits in the Chinese stock markets\n  In this paper, we investigate the cooling-off effect (opposite to the magnet\neffect) from two aspects. Firstly, from the viewpoint of dynamics, we study the\nexistence of the cooling-off effect by following the dynamical evolution of\nsome financial variables over a period of time before the stock price hits its\nlimit. Secondly, from the probability perspective, we investigate, with the\nlogit model, the existence of the cooling-off effect through analyzing the\nhigh-frequency data of all A-share common stocks traded on the Shanghai Stock\nExchange and the Shenzhen Stock Exchange from 2000 to 2011 and inspecting the\ntrading period from the opening phase prior to the moment that the stock price\nhits its limits. A comparison is made of the properties between up-limit hits\nand down-limit hits, and the possible difference will also be compared between\nbullish and bearish market state by dividing the whole period into three\nalternating bullish periods and three bearish periods. We find that the\ncooling-off effect emerges for both up-limit hits and down-limit hits, and the\ncooling-off effect of the down-limit hits is stronger than that of the up-limit\nhits. The difference of the cooling-off effect between bullish period and\nbearish period is quite modest. Moreover, we examine the sub-optimal orders\neffect, and infer that the professional individual investors and institutional\ninvestors play a positive role in the cooling-off effects. All these findings\nindicate that the price limit trading rule exerts a positive effect on\nmaintaining the stability of the Chinese stock markets.\n", "pos": 5.1169051581413045}
{"text": "Generative adversarial network-based approach to signal reconstruction from magnitude spectrograms\n  In this paper, we address the problem of reconstructing a time-domain signal\n(or a phase spectrogram) solely from a magnitude spectrogram. Since magnitude\nspectrograms do not contain phase information, we must restore or infer phase\ninformation to reconstruct a time-domain signal. One widely used approach for\ndealing with the signal reconstruction problem was proposed by Griffin and Lim.\nThis method usually requires many iterations for the signal reconstruction\nprocess and depending on the inputs, it does not always produce high-quality\naudio signals. To overcome these shortcomings, we apply a learning-based\napproach to the signal reconstruction problem by modeling the signal\nreconstruction process using a deep neural network and training it using the\nidea of a generative adversarial network. Experimental evaluations revealed\nthat our method was able to reconstruct signals faster with higher quality than\nthe Griffin-Lim method.\n", "pos": 5.509742884119289}
{"text": "The Flash ADC system and PMT waveform reconstruction for the Daya Bay Experiment\n  To better understand the energy response of the Antineutrino Detector (AD),\nthe Daya Bay Reactor Neutrino Experiment installed a full Flash ADC readout\nsystem on one AD that allowed for simultaneous data taking with the current\nreadout system. This paper presents the design, data acquisition, and\nsimulation of the Flash ADC system, and focuses on the PMT waveform\nreconstruction algorithms. For liquid scintillator calorimetry, the most\ncritical requirement to waveform reconstruction is linearity. Several common\nreconstruction methods were tested but the linearity performance was not\nsatisfactory. A new method based on the deconvolution technique was developed\nwith 1% residual non-linearity, which fulfills the requirement. The performance\nwas validated with both data and Monte Carlo (MC) simulations, and 1%\nconsistency between them has been achieved.\n", "pos": 5.414600915804031}
{"text": "Single versus Double Blind Reviewing at WSDM 2017\n  In this paper we study the implications for conference program committees of\nusing single-blind reviewing, in which committee members are aware of the names\nand affiliations of paper authors, versus double-blind reviewing, in which this\ninformation is not visible to committee members. WSDM 2017, the 10th ACM\nInternational ACM Conference on Web Search and Data Mining, performed a\ncontrolled experiment in which each paper was reviewed by four committee\nmembers. Two of these four reviewers were chosen from a pool of committee\nmembers who had access to author information; the other two were chosen from a\ndisjoint pool who did not have access to this information. This information\nasymmetry persisted through the process of bidding for papers, reviewing\npapers, and entering scores. Reviewers in the single-blind condition typically\nbid for 22% fewer papers, and preferentially bid for papers from top\ninstitutions. Once papers were allocated to reviewers, single-blind reviewers\nwere significantly more likely than their double-blind counterparts to\nrecommend for acceptance papers from famous authors and top institutions. The\nestimated odds multipliers are 1.63 for famous authors and 1.58 and 2.10 for\ntop universities and companies respectively, so the result is tangible. For\nfemale authors, the associated odds multiplier of 0.78 is not statistically\nsignificant in our study. However, a meta-analysis places this value in line\nwith that of other experiments, and in the context of this larger aggregate the\ngender effect is also statistically significant.\n", "pos": 5.5275011582468805}
{"text": "SPIDER: CMB polarimetry from the edge of space\n  SPIDER is a balloon-borne instrument designed to map the polarization of the\nmillimeter-wave sky at large angular scales. SPIDER targets the B-mode\nsignature of primordial gravitational waves in the cosmic microwave background\n(CMB), with a focus on mapping a large sky area with high fidelity at multiple\nfrequencies. SPIDER's first longduration balloon (LDB) flight in January 2015\ndeployed a total of 2400 antenna-coupled Transition Edge Sensors (TESs) at 90\nGHz and 150 GHz. In this work we review the design and in-flight performance of\nthe SPIDER instrument, with a particular focus on the measured performance of\nthe detectors and instrument in a space-like loading and radiation environment.\nSPIDER's second flight in December 2018 will incorporate payload upgrades and\nnew receivers to map the sky at 285 GHz, providing valuable information for\ncleaning polarized dust emission from CMB maps.\n", "pos": 5.330051396676788}
{"text": "Factoring the Cycle Aging Cost of Batteries Participating in Electricity Markets\n  When participating in electricity markets, owners of battery energy storage\nsystems must bid in such a way that their revenues will at least cover their\ntrue cost of operation. Since cycle aging of battery cells represents a\nsubstantial part of this operating cost, the cost of battery degradation must\nbe factored in these bids. However, existing models of battery degradation\neither do not fit market clearing software or do not reflect the actual battery\naging mechanism. In this paper we model battery cycle aging using a piecewise\nlinear cost function, an approach that provides a close approximation of the\ncycle aging mechanism of electrochemical batteries and can be incorporated\neasily into existing market dispatch programs. By defining the marginal aging\ncost of each battery cycle, we can assess the actual operating profitability of\nbatteries. A case study demonstrates the effectiveness of the proposed model in\nmaximizing the operating profit of a battery energy storage system taking part\nin the ISO New England energy and reserve markets.\n", "pos": 5.532778451800028}
{"text": "Generalized Gaussian Kernel Adaptive Filtering\n  The present paper proposes generalized Gaussian kernel adaptive filtering,\nwhere the kernel parameters are adaptive and data-driven. The Gaussian kernel\nis parametrized by a center vector and a symmetric positive definite (SPD)\nprecision matrix, which is regarded as a generalization of the scalar width\nparameter. These parameters are adaptively updated on the basis of a proposed\nleast-square-type rule to minimize the estimation error. The main contribution\nof this paper is to establish update rules for precision matrices on the SPD\nmanifold in order to keep their symmetric positive-definiteness. Different from\nconventional kernel adaptive filters, the proposed regressor is a superposition\nof Gaussian kernels with all different parameters, which makes such regressor\nmore flexible. The kernel adaptive filtering algorithm is established together\nwith a l1-regularized least squares to avoid overfitting and the increase of\ndimensionality of the dictionary. Experimental results confirm the validity of\nthe proposed method.\n", "pos": 5.562281723487772}
{"text": "Laplace approximation and the natural gradient for Gaussian process regression with the heteroscedastic Student-t model\n  This paper considers the Laplace method to derive approximate inference for\nthe Gaussian process (GP) regression in the location and scale parameters of\nthe Student-t probabilistic model. This allows both mean and variance of the\ndata to vary as a function of covariates with the attractive feature that the\nStudent-t model has been widely used as a useful tool for robustifying data\nanalysis. The challenge in the approximate inference for the GP regression with\nthe Student-t probabilistic model, lies in the analytical intractability of the\nposterior distribution and the lack of concavity of the log-likelihood\nfunction. We present the natural gradient adaptation for the estimation process\nwhich primarily relies on the property that the Student-t model naturally has\northogonal parametrization with respect to the location and scale paramaters.\nDue to this particular property of the model, we also introduce an alternative\nLaplace approximation by using the Fisher information matrix in place of the\nHessian matrix of the negative log-likelihood function. According to\nexperiments this alternative approximation provides very similar posterior\napproximations and predictive performance when compared to the traditional\nLaplace approximation. We also compare both of these Laplace approximations\nwith the Monte Carlo Markov Chain (MCMC) method. Moreover, we compare our\nheteroscedastic Student-t model and the GP regression with the heteroscedastic\nGaussian model. We also discuss how our approach can improve the inference\nalgorithm in cases where the probabilistic model assumed for the data is not\nlog-concave.\n", "pos": 5.255620988920364}
{"text": "UV Detector based on InAlN/GaN-on-Si HEMT Stack with Photo-to-Dark Current Ratio > 107\n  We demonstrate an InAlN/GaN-on-Si HEMT based UV detector with photo to dark\ncurrent ratio > 107. Ti/Al/Ni/Au metal stack was evaporated and rapid thermal\nannealed for Ohmic contacts to the 2D electron gas (2DEG) at the InAlN/GaN\ninterface while the channel + barrier was recess etched to a depth of 20 nm to\npinch-off the 2DEG between Source-Drain pads. Spectral responsivity (SR) of 34\nA/W at 367 nm was measured at 5 V in conjunction with very high photo to dark\ncurrent ratio of > 10^7. The photo to dark current ratio at a fixed bias was\nfound to be decreasing with increase in recess length of the PD. The fabricated\ndevices were found to exhibit a UV-to-visible rejection ratio of >103 with a\nlow dark current < 32 pA at 5 V. Transient measurements showed rise and fall\ntimes in the range of 3-4 ms. The gain mechanism was investigated and carrier\nlifetimes were estimated which matched well with those reported elsewhere.\n", "pos": 5.352695085539207}
{"text": "The additive groups of $\\mathbb{Z}$ and $\\mathbb{Q}$ with predicates for being square-free\n  We consider the four structures $(\\mathbb{Z}; \\mathrm{Sqf}^\\mathbb{Z})$,\n$(\\mathbb{Z}; <, \\mathrm{Sqf}^\\mathbb{Z})$, $(\\mathbb{Q};\n\\mathrm{Sqf}^\\mathbb{Q})$, and $(\\mathbb{Q}; <, \\mathrm{Sqf}^\\mathbb{Q})$ where\n$\\mathbb{Z}$ is the additive group of integers, $\\mathrm{Sqf}^\\mathbb{Z}$ is\nthe set of $a \\in \\mathbb{Z}$ such that $v_{p}(a) < 2$ for every prime $p$ and\ncorresponding $p$-adic valuation $v_{p}$, $\\mathbb{Q}$ and\n$\\mathrm{Sqf}^\\mathbb{Q}$ are defined likewise for rational numbers, and $<$\ndenotes the natural ordering on each of these domains. We prove that the second\nstructure is model-theoretically wild while the other three structures are\nmodel-theoretically tame. Moreover, all these results can be seen as examples\nwhere number-theoretic randomness yields model-theoretic consequences.\n", "pos": 5.352800669678034}
{"text": "The Evolution of Reputation-Based Cooperation in Regular Networks\n  Despite recent advances in reputation technologies, it is not clear how\nreputation systems can affect human cooperation in social networks. Although it\nis known that two of the major mechanisms in the evolution of cooperation are\nspatial selection and reputation-based reciprocity, theoretical study of the\ninterplay between both mechanisms remains almost uncharted. Here, we present a\nnew individual-based model for the evolution of reciprocal cooperation between\nreputation and networks. We comparatively analyze four of the leading moral\nassessment rules---shunning, image scoring, stern judging, and simple\nstanding---and base the model on the giving game in regular networks for\nCooperators, Defectors, and Discriminators. Discriminators rely on a proper\nmoral assessment rule. By using individual-based models, we show that the four\nassessment rules are differently characterized in terms of how cooperation\nevolves, depending on the benefit-to-cost ratio, the network-node degree, and\nthe observation and error conditions. Our findings show that the most tolerant\nrule---simple standing---is the most robust among the four assessment rules in\npromoting cooperation in regular networks.\n", "pos": 5.55683954550463}
{"text": "On the Runtime-Efficacy Trade-off of Anomaly Detection Techniques for Real-Time Streaming Data\n  Ever growing volume and velocity of data coupled with decreasing attention\nspan of end users underscore the critical need for real-time analytics. In this\nregard, anomaly detection plays a key role as an application as well as a means\nto verify data fidelity. Although the subject of anomaly detection has been\nresearched for over 100 years in a multitude of disciplines such as, but not\nlimited to, astronomy, statistics, manufacturing, econometrics, marketing, most\nof the existing techniques cannot be used as is on real-time data streams.\nFurther, the lack of characterization of performance -- both with respect to\nreal-timeliness and accuracy -- on production data sets makes model selection\nvery challenging. To this end, we present an in-depth analysis, geared towards\nreal-time streaming data, of anomaly detection techniques. Given the\nrequirements with respect to real-timeliness and accuracy, the analysis\npresented in this paper should serve as a guide for selection of the \"best\"\nanomaly detection technique. To the best of our knowledge, this is the first\ncharacterization of anomaly detection techniques proposed in very diverse set\nof fields, using production data sets corresponding to a wide set of\napplication domains.\n", "pos": 5.10516017384659}
{"text": "Travel time tomography with adaptive dictionaries\n  We develop a 2D travel time tomography method which regularizes the inversion\nby modeling groups of slowness pixels from discrete slowness maps, called\npatches, as sparse linear combinations of atoms from a dictionary. We propose\nto use dictionary learning during the inversion to adapt dictionaries to\nspecific slowness maps. This patch regularization, called the local model, is\nintegrated into the overall slowness map, called the global model. The local\nmodel considers small-scale variations using a sparsity constraint and the\nglobal model considers larger-scale features constrained using $\\ell_2$\nregularization. This strategy in a locally-sparse travel time tomography (LST)\napproach enables simultaneous modeling of smooth and discontinuous slowness\nfeatures. This is in contrast to conventional tomography methods, which\nconstrain models to be exclusively smooth or discontinuous. We develop a\n$\\textit{maximum a posteriori}$ formulation for LST and exploit the sparsity of\nslowness patches using dictionary learning. The LST approach compares favorably\nwith smoothness and total variation regularization methods on densely, but\nirregularly sampled synthetic slowness maps.\n", "pos": 5.478301417842221}
{"text": "Vibronic Ground-state Degeneracies and the Berry Phase: A Continuous Symmetry Perspective\n  We develop a geometric construction to prove the inevitability of the\nelectronic ground-state (adiabatic) Berry phase for a class of Jahn-Teller\nmodels with maximal continuous symmetries and N > 2 intersecting electronic\nstates. Given that vibronic ground-state degeneracy in JT models may be seen as\na consequence of the electronic Berry phase, and that any JT problem may be\nobtained from the subset we investigate in this letter by symmetry-breaking,\nour arguments reveal the fundamental origin of the vibronic ground-state\ndegeneracy of JT models.\n", "pos": 5.39420730750293}
{"text": "Degree weighted recurrence networks for the analysis of time series data\n  Recurrence networks are powerful tools used effectively in the nonlinear\nanalysis of time series data. The analysis in this context is done mostly with\nunweighted and undirected complex networks constructed with specific criteria\nfrom the time series. In this work, we propose a novel method to construct\n\"weighted recurrence network\"(WRN) from a time series and show how it can\nreveal useful information regarding the structure of a chaotic attractor, which\nthe usual unweighted recurrence network cannot provide. Especially, we find the\nnode strength distribution of the WRN, from every chaotic attractor follows a\npower law (with exponential tail) with the index characteristic to the fractal\nstructure of the attractor. This leads to a new class among complex networks,\nto which networks from all standard chaotic attractors are found to belong. In\naddition, we present generalized definitions for clustering coefficient and\ncharacteristic path length and show that these measures can effectively\ndiscriminate chaotic dynamics from white noise and $1/f$ colored noise. Our\nresults indicate that the WRN and the associated measures can become\npotentially important tools for the analysis of short and noisy time series\nfrom the real world systems as they are clearly demarked from that of noisy or\nstochastic systems.\n", "pos": 5.51400671761921}
{"text": "Prototypical Networks for Few-shot Learning\n  We propose prototypical networks for the problem of few-shot classification,\nwhere a classifier must generalize to new classes not seen in the training set,\ngiven only a small number of examples of each new class. Prototypical networks\nlearn a metric space in which classification can be performed by computing\ndistances to prototype representations of each class. Compared to recent\napproaches for few-shot learning, they reflect a simpler inductive bias that is\nbeneficial in this limited-data regime, and achieve excellent results. We\nprovide an analysis showing that some simple design decisions can yield\nsubstantial improvements over recent approaches involving complicated\narchitectural choices and meta-learning. We further extend prototypical\nnetworks to zero-shot learning and achieve state-of-the-art results on the\nCU-Birds dataset.\n", "pos": 5.533755006982183}
{"text": "GdRh$_2$Si$_2$: An exemplary tetragonal system for antiferromagnetic order with weak in-plane anisotropy\n  The anisotropy of magnetic properties commonly is introduced in textbooks\nusing the case of an antiferromagnetic system with Ising type anisotropy. This\nmodel presents huge anisotropic magnetization and a pronounced metamagnetic\ntransition and is well-known and well-documented both, in experiments and\ntheory. In contrast, the case of an antiferromagnetic $X$-$Y$ system with weak\nin-plane anisotropy is only poorly documented. We studied the anisotropic\nmagnetization of the compound GdRh$_2$Si$_2$ and found that it is a perfect\nmodel system for such a weak-anisotropy setting because the Gd$^{3+}$ ions in\nGdRh$_2$Si$_2$ have a pure spin moment of S=7/2 which orders in a simple AFM\nstructure with ${\\bf Q} = (001)$. We observed experimentally in $M(B)$ a\ncontinuous spin-flop transition and domain effects for field applied along the\n$[100]$- and the $[110]$-direction, respectively. We applied a mean field model\nfor the free energy to describe our data and combine it with an Ising chain\nmodel to account for domain effects. Our calculations reproduce the\nexperimental data very well. In addition, we performed magnetic X-ray\nscattering and X-ray magnetic circular dichroism measurements, which confirm\nthe AFM propagation vector to be ${\\bf Q} = (001)$ and indicate the absence of\npolarization on the rhodium atoms.\n", "pos": 5.252418010324635}
{"text": "Minor-free graphs have light spanners\n  We show that every $H$-minor-free graph has a light $(1+\\epsilon)$-spanner,\nresolving an open problem of Grigni and Sissokho and proving a conjecture of\nGrigni and Hung. Our lightness bound is\n\\[O\\left(\\frac{\\sigma_H}{\\epsilon^3}\\log \\frac{1}{\\epsilon}\\right)\\] where\n$\\sigma_H = |V(H)|\\sqrt{\\log |V(H)|}$ is the sparsity coefficient of\n$H$-minor-free graphs. That is, it has a practical dependency on the size of\nthe minor $H$. Our result also implies that the polynomial time approximation\nscheme (PTAS) for the Travelling Salesperson Problem (TSP) in $H$-minor-free\ngraphs by Demaine, Hajiaghayi and Kawarabayashi is an efficient PTAS whose\nrunning time is $2^{O_H\\left(\\frac{1}{\\epsilon^4}\\log\n\\frac{1}{\\epsilon}\\right)}n^{O(1)}$ where $O_H$ ignores dependencies on the\nsize of $H$. Our techniques significantly deviate from existing lines of\nresearch on spanners for $H$-minor-free graphs, but build upon the work of\nChechik and Wulff-Nilsen for spanners of general graphs.\n", "pos": 5.212235211260133}
{"text": "Comment on Photothermal radiometry parametric identifiability theory for reliable and unique nondestructive coating thickness and thermophysical measurements, J. Appl. Phys. 121(9), 095101 (2017)\n  A recent paper [X. Guo, A. Mandelis, J. Tolev and K. Tang, J. Appl. Phys.,\n121, 095101 (2017)] intends to demonstrate that from the photothermal\nradiometry signal obtained on a coated opaque sample in 1D transfer, one should\nbe able to identify separately the following three parameters of the coating:\nthermal diffusivity, thermal conductivity and thickness. In this comment, it is\nshown that the three parameters are correlated in the considered experimental\narrangement, the identifiability criterion is in error and the thickness\ninferred therefrom is not trustable.\n", "pos": 5.6281889262147216}
{"text": "Momentum and Stochastic Momentum for Stochastic Gradient, Newton, Proximal Point and Subspace Descent Methods\n  In this paper we study several classes of stochastic optimization algorithms\nenriched with heavy ball momentum. Among the methods studied are: stochastic\ngradient descent, stochastic Newton, stochastic proximal point and stochastic\ndual subspace ascent. This is the first time momentum variants of several of\nthese methods are studied. We choose to perform our analysis in a setting in\nwhich all of the above methods are equivalent. We prove global nonassymptotic\nlinear convergence rates for all methods and various measures of success,\nincluding primal function values, primal iterates (in L2 sense), and dual\nfunction values. We also show that the primal iterates converge at an\naccelerated linear rate in the L1 sense. This is the first time a linear rate\nis shown for the stochastic heavy ball method (i.e., stochastic gradient\ndescent method with momentum). Under somewhat weaker conditions, we establish a\nsublinear convergence rate for Cesaro averages of primal iterates. Moreover, we\npropose a novel concept, which we call stochastic momentum, aimed at decreasing\nthe cost of performing the momentum step. We prove linear convergence of\nseveral stochastic methods with stochastic momentum, and show that in some\nsparse data regimes and for sufficiently small momentum parameters, these\nmethods enjoy better overall complexity than methods with deterministic\nmomentum. Finally, we perform extensive numerical testing on artificial and\nreal datasets, including data coming from average consensus problems.\n", "pos": 5.683468744073611}
{"text": "Discrete Time Dynamic Programming with Recursive Preferences: Optimality and Applications\n  This paper provides an alternative approach to the theory of dynamic\nprogramming, designed to accommodate the kinds of recursive preference\nspecifications that have become popular in economic and financial analysis,\nwhile still supporting traditional additively separable rewards. The approach\nexploits the theory of monotone convex operators, which turns out to be well\nsuited to dynamic maximization. The intuition is that convexity is preserved\nunder maximization, so convexity properties found in preferences extend\nnaturally to the Bellman operator.\n", "pos": 5.578907391385327}
{"text": "Realizing an optimization approach inspired from Piagets theory on cognitive development\n  The objective of this paper is to introduce an artificial intelligence based\noptimization approach, which is inspired from Piagets theory on cognitive\ndevelopment. The approach has been designed according to essential processes\nthat an individual may experience while learning something new or improving his\n/ her knowledge. These processes are associated with the Piagets ideas on an\nindividuals cognitive development. The approach expressed in this paper is a\nsimple algorithm employing swarm intelligence oriented tasks in order to\novercome single-objective optimization problems. For evaluating effectiveness\nof this early version of the algorithm, test operations have been done via some\nbenchmark functions. The obtained results show that the approach / algorithm\ncan be an alternative to the literature in terms of single-objective\noptimization. The authors have suggested the name: Cognitive Development\nOptimization Algorithm (CoDOA) for the related intelligent optimization\napproach.\n", "pos": 5.565651392650941}
{"text": "The Kontsevich tetrahedral flow in 2D: a toy model\n  In the paper \"Formality conjecture\" (1996) Kontsevich designed a universal\nflow $\\dot{\\mathcal{P}}=\\mathcal{Q}_{a:b}(\\mathcal{P})=a\\Gamma_{1}+b\\Gamma_{2}$\non the spaces of Poisson structures $\\mathcal{P}$ on all affine manifolds of\ndimension $n \\geqslant 2$. We prove a claim from $\\textit{loc. cit.}$ stating\nthat if $n=2$, the flow $\\mathcal{Q}_{1:0}=\\Gamma_{1}(\\mathcal{P})$ is\nPoisson-cohomology trivial: $\\Gamma_{1}(\\mathcal{P})$ is the Schouten bracket\nof $\\mathcal{P}$ with $\\mathcal{X}$, for some vector field $\\mathcal{X}$; we\nexamine the structure of the space of solutions $\\mathcal{X}$. Both the\nconstruction of differential polynomials $\\Gamma_{1}(\\mathcal{P})$ and\n$\\Gamma_{2}(\\mathcal{P})$ and the technique to study them remain valid in\nhigher dimensions $n \\geqslant 3$, but neither the trivializing vector field\n$\\mathcal{X}$ nor the setting $b:=0$ survive at $n\\geqslant 3$, where the\nbalance is $a:b=1:6$.\n", "pos": 5.525655580452942}
{"text": "Spin glasses : experimental signatures and salient outcomes\n  Within the wide class of disordered materials, spin glasses occupy a special\nplace because of their conceptually simple definition of randomly interacting\nspins. Their modelling has triggered spectacular developments of\nout-of-equilibrium statistical physics, as well analytically as numerically,\nopening the way to a new vision of glasses in general. \"Real\" spin glasses are\ndisordered magnetic materials which can be very diverse from the chemist's\npoint of view, but all share a number of common properties, laying down the\ndefinition of generic spin glass behaviour. This paper aims at giving to\nnon-specialist readers an idea of what spin glasses are from an\nexperimentalist's point of view, describing as simply as possible their main\nfeatures as they can be observed in the laboratory, referring to numerous\ndetailed publications for more substantial discussions and for all theoretical\ndevelopments, which are hardly sketched here. We strived to provide the readers\nwho are interested in other glassy materials with some clues about the\npotential of spin glasses for improving their understanding of disordered\nmatter. At least, arousing their curiosity for this fascinating subject will be\nconsidered a success.\n", "pos": 5.339526855218093}
{"text": "Real intersection homology\n  We present a definition of intersection homology for real algebraic varieties\nthat is analogous to Goresky and MacPherson's original definition of\nintersection homology for complex varieties.\n", "pos": 5.497229411625569}
{"text": "SHINE: Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction\n  In online social networks people often express attitudes towards others,\nwhich forms massive sentiment links among users. Predicting the sign of\nsentiment links is a fundamental task in many areas such as personal\nadvertising and public opinion analysis. Previous works mainly focus on textual\nsentiment classification, however, text information can only disclose the \"tip\nof the iceberg\" about users' true opinions, of which the most are unobserved\nbut implied by other sources of information such as social relation and users'\nprofile. To address this problem, in this paper we investigate how to predict\npossibly existing sentiment links in the presence of heterogeneous information.\nFirst, due to the lack of explicit sentiment links in mainstream social\nnetworks, we establish a labeled heterogeneous sentiment dataset which consists\nof users' sentiment relation, social relation and profile knowledge by\nentity-level sentiment extraction method. Then we propose a novel and flexible\nend-to-end Signed Heterogeneous Information Network Embedding (SHINE) framework\nto extract users' latent representations from heterogeneous networks and\npredict the sign of unobserved sentiment links. SHINE utilizes multiple deep\nautoencoders to map each user into a low-dimension feature space while\npreserving the network structure. We demonstrate the superiority of SHINE over\nstate-of-the-art baselines on link prediction and node recommendation in two\nreal-world datasets. The experimental results also prove the efficacy of SHINE\nin cold start scenario.\n", "pos": 5.5231748306282515}
{"text": "Electronic structure of ultralong-range Rydberg pentaatomic molecules with two polar diatomic molecules\n  We explore the electronic structure of ultralong-range pentaatomic Rydberg\nmolecules from a merger of a Rydberg atom and two ground state heteronuclear\ndiatomic molecules. Our focus is on the interaction of Rb($23s$) and Rb($n=20$,\n$l\\ge 3$) Rydberg states with ground and rotationally excited KRb diatomic\npolar molecules. For symmetric and asymmetric configurations of the pentaatomic\nRydberg molecule, we investigate the metamorphosis of the Born-Oppenheimer\npotential curves, essential for the binding of the molecule, with varying\ndistance from the Rydberg core and analyze the alignment and orientation of the\npolar diatomic molecules.\n", "pos": 5.546222212026029}
{"text": "Comparing Covariate Prioritization via Matching to Machine Learning Methods for Causal Inference using Five Empirical Applications\n  When investigators seek to estimate causal effects, they often assume that\nselection into treatment is based only on observed covariates. Under this\nidentification strategy, analysts must adjust for observed confounders. While\nbasic regression models have long been the dominant method of statistical\nadjustment, more robust methods based on matching or weighting have become more\ncommon. Of late, even more flexible methods based on machine learning methods\nhave been developed for statistical adjustment. These machine learning methods\nare designed to be black box methods with little input from the researcher.\nRecent research used a data competition to evaluate various methods of\nstatistical adjustment and found that black box methods out performed all other\nmethods of statistical adjustment. Matching methods with covariate\nprioritization are designed for direct input from substantive investigators in\ndirect contrast to black methods. In this article, we use a different research\ndesign to compare matching with covariate prioritization to black box methods.\nWe use black box methods to replicate results from five studies where matching\nwith covariate prioritization was used to customize the statistical adjustment\nin direct response to substantive expertise. We find little difference across\nthe methods. We conclude with advice for investigators.\n", "pos": 5.678403958191976}
{"text": "Diversity driven Attention Model for Query-based Abstractive Summarization\n  Abstractive summarization aims to generate a shorter version of the document\ncovering all the salient points in a compact and coherent fashion. On the other\nhand, query-based summarization highlights those points that are relevant in\nthe context of a given query. The encode-attend-decode paradigm has achieved\nnotable success in machine translation, extractive summarization, dialog\nsystems, etc. But it suffers from the drawback of generation of repeated\nphrases. In this work we propose a model for the query-based summarization task\nbased on the encode-attend-decode paradigm with two key additions (i) a query\nattention model (in addition to document attention model) which learns to focus\non different portions of the query at different time steps (instead of using a\nstatic representation for the query) and (ii) a new diversity based attention\nmodel which aims to alleviate the problem of repeating phrases in the summary.\nIn order to enable the testing of this model we introduce a new query-based\nsummarization dataset building on debatepedia. Our experiments show that with\nthese two additions the proposed model clearly outperforms vanilla\nencode-attend-decode models with a gain of 28% (absolute) in ROUGE-L scores.\n", "pos": 5.543314783932762}
{"text": "Dimension Splitting and a Long Time-Step Multi-Dimensional Scheme for Atmospheric Transport\n  Dimensionally split advection schemes are attractive for atmospheric\nmodelling due to their efficiency and accuracy in each spatial dimension.\nAccurate long time-steps can be achieved without significant cost using the\nflux-form semi-Lagrangian technique. The dimensionally split scheme used here\nis constructed from the one-dimensional Piecewise Parabolic Method and extended\nto two dimensions using COSMIC splitting. The dimensionally split scheme is\ncompared with a genuinely multi-dimensional, method of lines scheme with\nimplicit time-stepping which is stable for large Courant numbers.\nTwo-dimensional advection test cases on Cartesian planes are proposed that\navoid the complexities of a spherical domain or multi-panel meshes. These are\nsolid body rotation, horizontal advection over orography and deformational\nflow. The test cases use distorted meshes either to represent sloping terrain\nor to mimic the distortions of a cubed sphere.\nSuch mesh distortions are expected to accentuate the errors associated with\ndimension splitting, however, the dimensionally split scheme is very accurate\non orthogonal meshes and accuracy decreases only a little in the presence of\nlarge mesh distortions. The dimensionally split scheme also loses some accuracy\nwhen long time-steps are used. The multi-dimensional scheme is almost entirely\ninsensitive to mesh distortions and asymptotes to second-order accuracy at high\nresolution. As is expected for implicit time-stepping, phase errors occur when\nusing long time-steps but the spatially well resolved features are advected at\nthe correct speed and the multi-dimensional scheme is always stable.\nAn estimate of computational cost reveals that the implicit scheme is the\nmost expensive, particularly for large Courant numbers. If the\nmulti-dimensional scheme is used instead with explicit time-stepping, the cost\nbecomes similar to the dimensionally split scheme.\n", "pos": 5.377479242061119}
{"text": "Analytic and Numerical Analysis of Singular Cauchy integrals with exponential-type weights\n  Let $I=(c,d)$, $c < 0 < d$, $Q\\in C^1: I\\rightarrow[0,\\infty)$ be a function\nwith given regularity behavior on $I$. Write $w:=\\exp(-Q)$ on $I$ and assume\nthat $\\int_I x^nw^2(x)dx<\\infty$ for all $n=0,1,2,\\ldots$. For $x\\in I$, we\nconsider the problem of the analytic and numerical approximation of the Cauchy\nprincipal value integral: \\begin{equation*} I[f;x]:=\\lim_{\\varepsilon \\to 0+}\n\\left( \\int_{c}^{x-\\varepsilon} w^2(t)\\frac{f(t)}{t-x}dt+\n\\int_{x+\\varepsilon}^{d} w^2(t)\\frac{f(t)}{t-x}dt. \\right) \\end{equation*} for\na class of functions $f: I\\rightarrow \\mathbb{R^+}$ for which $I[f;x]$ is\nfinite. In [1-4], the first two authors studied this problem and some of its\napplications for even exponential weights $w$ on $(-\\infty,\\infty)$ of smooth\npolynomial decay at $\\pm \\infty$ and given regularity.\n", "pos": 5.634396641495914}
{"text": "The toric Frobenius morphism and a conjecture of Orlov\n  We combine the Bondal-Uehara method for producing exceptional collections on\ntoric varieties with a result of the first author and Favero to expand the set\nof varieties satisfying Orlov's Conjecture on derived dimension.\n", "pos": 5.1366468538273145}
